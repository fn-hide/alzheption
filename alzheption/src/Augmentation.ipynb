{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 06:39:41.165033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742254781.184089  283704 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742254781.190225  283704 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-18 06:39:41.209391: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torchvision as tv\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from alzheption.clahe import Clahe\n",
    "from alzheption.extractor import AlzheptionExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0, std=25):\n",
    "    np_img = np.array(image, dtype=np.float32)\n",
    "    noise = np.random.normal(mean, std, np_img.shape).astype(np.float32)\n",
    "    np_img = np.clip(np_img + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../asset/dataset_jpg_brightness_balance/'\n",
    "\n",
    "dataset = tv.datasets.ImageFolder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_aug = [\"rotate\"]\n",
    "dir_path = f'../../asset/dataset_jpg_brightness_balance_augmentation_{\"_\".join([aug for aug in list_aug])}/'\n",
    "shutil.rmtree(dir_path, ignore_errors=True)\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "idx_transform = 0\n",
    "for idx, (img, label) in enumerate(dataset):\n",
    "    name_class = dataset.classes[label]\n",
    "    dir_label = os.path.join(dir_path, name_class)\n",
    "    os.makedirs(dir_label, exist_ok=True)\n",
    "    \n",
    "    img.save(os.path.join(dir_label, f\"img_{idx}_original.jpg\"))\n",
    "    \n",
    "    transformations = {\n",
    "        # \"hflip\": tv.transforms.functional.hflip(img),\n",
    "        # \"vflip\": tv.transforms.functional.vflip(img),\n",
    "        # \"rotate_90\": tv.transforms.functional.rotate(img, 90, expand=True),\n",
    "        \"random_rotate\": tv.transforms.functional.rotate(img, random.uniform(-90, 90), expand=True),\n",
    "        # \"random_crop\": tv.transforms.RandomResizedCrop(size=img.size, scale=(0.8, 1.0))(img),\n",
    "        # \"random_shear\": tv.transforms.RandomAffine(degrees=0, shear=20)(img),\n",
    "        # \"blur\": img.filter(ImageFilter.GaussianBlur(radius=random.uniform(1, 2))),\n",
    "        # \"brightness_contrast\": tv.transforms.ColorJitter(brightness=0.2, contrast=0.2)(img),\n",
    "        # # \"random_noise\": add_gaussian_noise(img),\n",
    "        # \"cutout\": tv.transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), value=0)(tv.transforms.ToTensor()(img)).permute(1, 2, 0),\n",
    "    }\n",
    "    for aug_name, aug_img in transformations.items():\n",
    "        if list(transformations.keys())[idx_transform] != aug_name:\n",
    "            continue\n",
    "        \n",
    "        if isinstance(aug_img, torch.Tensor):  # Untuk cutout, ubah ke PIL Image\n",
    "            aug_img = tv.transforms.ToPILImage()(aug_img.numpy())\n",
    "        aug_img.save(os.path.join(dir_label, f\"img_{idx}_{aug_name}.jpg\"), format=\"JPEG\")\n",
    "    \n",
    "    if idx_transform == len(transformations) - 1:\n",
    "        idx_transform = 0\n",
    "    else:\n",
    "        idx_transform += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = tv.transforms.functional.hflip(img)\n",
    "# img1.save(os.path.join(dir_label, f\"img_{idx}_1.jpg\"))\n",
    "\n",
    "# img2 = tv.transforms.functional.rotate(img, 45)\n",
    "# img2.save(os.path.join(dir_label, f\"img_{idx}_2.jpg\"))\n",
    "\n",
    "# img3 = tv.transforms.functional.vflip(img)\n",
    "# img3.save(os.path.join(dir_label, f\"img_{idx}_3.jpg\"))\n",
    "\n",
    "# img4 = tv.transforms.functional.rotate(img, 90)\n",
    "# img4.save(os.path.join(dir_label, f\"img_{idx}_4.jpg\"))\n",
    "\n",
    "# img5 = tv.transforms.functional.rotate(img, 45)\n",
    "# img5.save(os.path.join(dir_label, f\"img_{idx}_5.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
